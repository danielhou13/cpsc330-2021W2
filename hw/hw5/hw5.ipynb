{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Evaluation metrics\n",
    "### Associated lectures: [Lectures 9, 10](https://ubc-cs.github.io/cpsc330/README.html) \n",
    "\n",
    "**Due date: Monday, Feb 28, 2022 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tests_hw5\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:3}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Precision, recall, and f1 score by hand <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of predicting whether a patient has a disease or not. Below are confusion matrices of two machine learning models: Model A and Model B. \n",
    "\n",
    "- Model A\n",
    "\n",
    "|    Actual/Predicted      | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 18 | 22 |\n",
    "| **Actual no disease**       | 10 | 100 |\n",
    "\n",
    "\n",
    "- Model B\n",
    "\n",
    "|    Actual/Predicted      | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 23 | 17 |\n",
    "| **Actual no disease**       | 20 | 90 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Positive vs. negative class \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Precision, recall, and f1 score depend upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual disease class is likely to be the positive class because that is the thing we are interested in finding out here. Having the disease is likely more interesting and important for us to know than them not having the disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accuracy\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "We'll store all metrics associated with Model A and Model B in the `results_dict` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"A\": {}, \"B\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"accuracy\"] = (18 + 100) / (18+22+10+100)\n",
    "results_dict[\"B\"][\"accuracy\"] = (23+90) / (23+17+20+90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_1(\n",
    "    results_dict[\"A\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_2_2(\n",
    "    results_dict[\"B\"][\"accuracy\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A         B\n",
       "accuracy  0.786667  0.753333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Which model would you pick? \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based solely on the accuracy metric, I would pick model A because it is higher than model B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Precision, recall, f1-score\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Calculate precision, recall, f1-score for Model A and Model B manually, without using `scikit-learn` tools. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"precision\"] = 18 /(18+10)\n",
    "results_dict[\"B\"][\"precision\"] = 23/(23+20)\n",
    "results_dict[\"A\"][\"recall\"] = 18 / (18+22)\n",
    "results_dict[\"B\"][\"recall\"] = 23 / (23+17)\n",
    "results_dict[\"A\"][\"f1\"] = 2 * (results_dict[\"A\"][\"precision\"] * results_dict[\"A\"][\"recall\"])/(results_dict[\"A\"][\"precision\"] + results_dict[\"A\"][\"recall\"])\n",
    "results_dict[\"B\"][\"f1\"] = 2 * (results_dict[\"B\"][\"precision\"] * results_dict[\"B\"][\"recall\"])/(results_dict[\"B\"][\"precision\"] + results_dict[\"B\"][\"recall\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_1(\n",
    "    results_dict[\"A\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_2(\n",
    "    results_dict[\"B\"][\"precision\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_3(\n",
    "    results_dict[\"A\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_4(\n",
    "    results_dict[\"B\"][\"recall\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_5(\n",
    "    results_dict[\"A\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "assert tests_hw5.ex1_4_6(\n",
    "    results_dict[\"B\"][\"f1\"]\n",
    "), \"Your answer is incorrect, see traceback above.\"\n",
    "print(\"Success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataframe with all results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.753333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.534884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.554217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         B\n",
       "accuracy   0.786667  0.753333\n",
       "precision  0.642857  0.534884\n",
       "recall     0.450000  0.575000\n",
       "f1         0.529412  0.554217"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Discussion\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Which metric is more informative in this problem? Why? \n",
    "2. Which model would you pick based on this information? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I believe that the recall is more informative because we really want to make sure that everybody that did have the disease was able to be identified by the model. Since the recall is quite low, we see that there is a lot of false negatives, or cases where the model thought they did not have the disease, which can have serious implications in real-world applications. \n",
    "2. Given this, I would pick model B because the recall score is much better than the recall score for model A. That being said, both are still quite low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 1.6 \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Provide 2 to 3 example classification datasets (with links) where accuracy metric would be misleading. Discuss which evaluation metric would be more appropriate for each dataset. You may consider datasets we have used in this course so far. You could also look up datasets on Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classification evaluation metrics using `sklearn` <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In class, we looked at credit card fraud dataset which is a classic example of an imbalanced dataset. \n",
    "\n",
    "Another example is customer churn datasets. [Customer churn](https://en.wikipedia.org/wiki/Customer_attrition) refers to the notion of customers leaving a subscription service like Netflix. In this exercise, we will try to predict customer churn in a dataset where most of the customers stay with the service and a small minority cancel their subscription. To start, please download the [Kaggle telecom customer churn dataset](https://www.kaggle.com/becksddf/churn-in-telecoms-dataset). Once you have the data, you should be able to run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code below reads the data CSV as a pandas dataframe and splits it into 70% train and 30% test. \n",
    "\n",
    "Note that `churn` column in the dataset is the target. \"True\" means the customer left the subscription (churned) and \"False\" means they stayed.\n",
    "\n",
    "> Note that for this kind of problem a more appropriate technique is something called survival analysis and we'll be talking about it later in the course. For now, we'll just treat it as a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>NE</td>\n",
       "      <td>70</td>\n",
       "      <td>415</td>\n",
       "      <td>421-8535</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.4</td>\n",
       "      <td>86</td>\n",
       "      <td>36.28</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>17.40</td>\n",
       "      <td>256.6</td>\n",
       "      <td>101</td>\n",
       "      <td>11.55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>WI</td>\n",
       "      <td>67</td>\n",
       "      <td>510</td>\n",
       "      <td>417-2265</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>134</td>\n",
       "      <td>18.55</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>12.10</td>\n",
       "      <td>91.2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.10</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>NJ</td>\n",
       "      <td>122</td>\n",
       "      <td>415</td>\n",
       "      <td>327-9341</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>34</td>\n",
       "      <td>146.4</td>\n",
       "      <td>104</td>\n",
       "      <td>24.89</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>7.62</td>\n",
       "      <td>220.0</td>\n",
       "      <td>91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NV</td>\n",
       "      <td>107</td>\n",
       "      <td>510</td>\n",
       "      <td>419-9688</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>234.1</td>\n",
       "      <td>91</td>\n",
       "      <td>39.80</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>13.86</td>\n",
       "      <td>282.5</td>\n",
       "      <td>100</td>\n",
       "      <td>12.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>HI</td>\n",
       "      <td>105</td>\n",
       "      <td>510</td>\n",
       "      <td>364-8128</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>116</td>\n",
       "      <td>21.32</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>22.23</td>\n",
       "      <td>241.6</td>\n",
       "      <td>104</td>\n",
       "      <td>10.87</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>WY</td>\n",
       "      <td>126</td>\n",
       "      <td>408</td>\n",
       "      <td>339-9798</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>126</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>20.95</td>\n",
       "      <td>285.3</td>\n",
       "      <td>104</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>WV</td>\n",
       "      <td>70</td>\n",
       "      <td>510</td>\n",
       "      <td>348-3777</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>143.4</td>\n",
       "      <td>72</td>\n",
       "      <td>24.38</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>14.45</td>\n",
       "      <td>127.9</td>\n",
       "      <td>68</td>\n",
       "      <td>5.76</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>NJ</td>\n",
       "      <td>125</td>\n",
       "      <td>415</td>\n",
       "      <td>406-6400</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>182.3</td>\n",
       "      <td>64</td>\n",
       "      <td>30.99</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>11.88</td>\n",
       "      <td>171.6</td>\n",
       "      <td>96</td>\n",
       "      <td>7.72</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NE</td>\n",
       "      <td>159</td>\n",
       "      <td>415</td>\n",
       "      <td>362-5111</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>189.1</td>\n",
       "      <td>105</td>\n",
       "      <td>32.15</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>20.92</td>\n",
       "      <td>242.0</td>\n",
       "      <td>106</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>PA</td>\n",
       "      <td>106</td>\n",
       "      <td>408</td>\n",
       "      <td>403-9167</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>133.7</td>\n",
       "      <td>45</td>\n",
       "      <td>22.73</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>15.96</td>\n",
       "      <td>181.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code phone number international plan  \\\n",
       "1402    NE              70        415     421-8535                 no   \n",
       "1855    WI              67        510     417-2265                 no   \n",
       "633     NJ             122        415     327-9341                 no   \n",
       "1483    NV             107        510     419-9688                yes   \n",
       "2638    HI             105        510     364-8128                 no   \n",
       "...    ...             ...        ...          ...                ...   \n",
       "2154    WY             126        408     339-9798                yes   \n",
       "3089    WV              70        510     348-3777                 no   \n",
       "1766    NJ             125        415     406-6400                 no   \n",
       "1122    NE             159        415     362-5111                 no   \n",
       "1346    PA             106        408     403-9167                yes   \n",
       "\n",
       "     voice mail plan  number vmail messages  total day minutes  \\\n",
       "1402              no                      0              213.4   \n",
       "1855              no                      0              109.1   \n",
       "633              yes                     34              146.4   \n",
       "1483              no                      0              234.1   \n",
       "2638              no                      0              125.4   \n",
       "...              ...                    ...                ...   \n",
       "2154              no                      0              197.6   \n",
       "3089             yes                     30              143.4   \n",
       "1766              no                      0              182.3   \n",
       "1122              no                      0              189.1   \n",
       "1346              no                      0              133.7   \n",
       "\n",
       "      total day calls  total day charge  ...  total eve calls  \\\n",
       "1402               86             36.28  ...               77   \n",
       "1855              134             18.55  ...               76   \n",
       "633               104             24.89  ...              103   \n",
       "1483               91             39.80  ...              105   \n",
       "2638              116             21.32  ...               95   \n",
       "...               ...               ...  ...              ...   \n",
       "2154              126             33.59  ...              112   \n",
       "3089               72             24.38  ...               92   \n",
       "1766               64             30.99  ...              121   \n",
       "1122              105             32.15  ...              147   \n",
       "1346               45             22.73  ...              107   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "1402             17.40                256.6                101   \n",
       "1855             12.10                 91.2                 86   \n",
       "633               7.62                220.0                 91   \n",
       "1483             13.86                282.5                100   \n",
       "2638             22.23                241.6                104   \n",
       "...                ...                  ...                ...   \n",
       "2154             20.95                285.3                104   \n",
       "3089             14.45                127.9                 68   \n",
       "1766             11.88                171.6                 96   \n",
       "1122             20.92                242.0                106   \n",
       "1346             15.96                181.9                 89   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "1402               11.55                 5.7                 4   \n",
       "1855                4.10                10.9                 5   \n",
       "633                 9.90                15.6                 4   \n",
       "1483               12.71                10.0                 3   \n",
       "2638               10.87                11.4                 9   \n",
       "...                  ...                 ...               ...   \n",
       "2154               12.84                12.5                 8   \n",
       "3089                5.76                 9.4                 4   \n",
       "1766                7.72                11.6                 7   \n",
       "1122               10.89                10.4                 5   \n",
       "1346                8.19                10.7                 2   \n",
       "\n",
       "      total intl charge  customer service calls  churn  \n",
       "1402               1.54                       1  False  \n",
       "1855               2.94                       2  False  \n",
       "633                4.21                       2  False  \n",
       "1483               2.70                       1  False  \n",
       "2638               3.08                       2  False  \n",
       "...                 ...                     ...    ...  \n",
       "2154               3.38                       2  False  \n",
       "3089               2.54                       3  False  \n",
       "1766               3.13                       2  False  \n",
       "1122               2.81                       1   True  \n",
       "1346               2.89                       1   True  \n",
       "\n",
       "[2333 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.csv\", encoding=\"utf-8\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution of target values\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Examine the distribution of target values in the train split. Do you see class imbalance? If yes, do we need to deal with it? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1984\n",
       "True      349\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the train set, that there is a big imbalance between the number of \"False\" cases and the number of \"True\" cases. According to the data set, it says that the \"dataset where most of the customers stay with the service and a small minority cancel their subscription\", so we already know that there would be more cases of \"False\" than true. Therefore we do need to deal with it because every time we see an instance of \"True\" in this majority false dataset, it should have more impact than if we see \"False\" like we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 2.2 EDA \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Come up with **two** exploratory questions you would like to answer and explore those. Briefly discuss your results in 1-3 sentences.\n",
    "\n",
    "You are welcome to use `pandas_profiling` (see Lecture 10) but you don't have to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Column transformer \n",
    "rubric={points:10}\n",
    "\n",
    "The code below creates `X_train`, `y_train`, `X_test`, `y_test` for you. \n",
    "In preparation for building a classifier, set up a `ColumnTransformer` that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. Remember that by default `ColumnTransformer` will drop any columns that aren't accounted for when it's created.\n",
    "\n",
    "In each case, briefly explain your rationale with 1-2 sentences. You do not need an explanation for every feature, but for every group of features that are being transformed the same way. For example, \"I am doing transformation X to the following categorical features: `a`, `b`, `c` because of reason Y,\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2333 entries, 1402 to 1346\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state                   2333 non-null   object \n",
      " 1   account length          2333 non-null   int64  \n",
      " 2   area code               2333 non-null   int64  \n",
      " 3   phone number            2333 non-null   object \n",
      " 4   international plan      2333 non-null   object \n",
      " 5   voice mail plan         2333 non-null   object \n",
      " 6   number vmail messages   2333 non-null   int64  \n",
      " 7   total day minutes       2333 non-null   float64\n",
      " 8   total day calls         2333 non-null   int64  \n",
      " 9   total day charge        2333 non-null   float64\n",
      " 10  total eve minutes       2333 non-null   float64\n",
      " 11  total eve calls         2333 non-null   int64  \n",
      " 12  total eve charge        2333 non-null   float64\n",
      " 13  total night minutes     2333 non-null   float64\n",
      " 14  total night calls       2333 non-null   int64  \n",
      " 15  total night charge      2333 non-null   float64\n",
      " 16  total intl minutes      2333 non-null   float64\n",
      " 17  total intl calls        2333 non-null   int64  \n",
      " 18  total intl charge       2333 non-null   float64\n",
      " 19  customer service calls  2333 non-null   int64  \n",
      "dtypes: float64(8), int64(8), object(4)\n",
      "memory usage: 382.8+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X_train = train_df.drop(columns=[\"churn\"])\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "\n",
    "y_train = train_df[\"churn\"]\n",
    "y_test = test_df[\"churn\"]\n",
    "\n",
    "X_train.info()\n",
    "X_train.describe(include=\"all\")\n",
    "\n",
    "numeric_features = [\"account length\",\n",
    "                    \"number vmail messages\",\n",
    "                   \"total day minutes\",\n",
    "                   \"total day calls\",\n",
    "                   \"total day charge\",\n",
    "                   \"total eve minutes\",\n",
    "                   \"total eve calls\",\n",
    "                   \"total eve charge\",\n",
    "                   \"total night minutes\",\n",
    "                   \"total night calls\",\n",
    "                   \"total night charge\",\n",
    "                   \"total intl minutes\",\n",
    "                   \"total intl calls\",\n",
    "                   \"total intl charge\",\n",
    "                   \"customer service calls\"]\n",
    "categorical_features = [\"state\", \"area code\"]\n",
    "binary_features = [\"international plan\", \"voice mail plan\"]\n",
    "drop_features = [\"phone number\"]\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (make_pipeline(SimpleImputer(), StandardScaler()), numeric_features), \n",
    "    (make_pipeline(SimpleImputer(strategy=\"constant\", fill_value=\"missing\"), OneHotEncoder(handle_unknown=\"ignore\", sparse=False)), categorical_features),\n",
    "    (make_pipeline(SimpleImputer(strategy=\"most_frequent\"), OneHotEncoder(drop=\"if_binary\", dtype=int)), binary_features),\n",
    "    (\"drop\", drop_features),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric features: We apply scaling to our numeric features, which mostly consist of number of calls in day, eve, night and international. Since they have different ranges, where number of calls is likely a lot less than minutes called for instance, we want to scale them so no features overshadow another.\n",
    "Categorical features: Given that state is in text form, we want to convert it to a manner that our model on operate on. On the other hand, for area code, it is only numeric looking, so it still represents a manner of classifying different areas in a state, therefore, we want to give it the same treatment as the states, by using one hot encoding.\n",
    "Binary Features: Both of these features are binary, so we apply one hot encoding to both of them so our model can incorporate them.\n",
    "Lastly, for drop features, we drop phone number because each person will have their own unique number, so each phone number would end up being a new feature. Not only does this make computation more time-consuming, the model wont learn any useful relations as there will only be one example where the feature is non-zero.\n",
    "\n",
    "We do simple imputing for all of them just in case we run into a situation where another version of the dataset or the test set does have missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualizing the transformed data \n",
    "rubric={points:4}\n",
    "\n",
    "Fit and transform your `ColumnTransformer` on your training set. Print the first 5 rows of the transformed data as a dataframe (not numpy array). See lecture 10 for code that can get you the new column names after transforming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline-1': Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
       "                 ('standardscaler', StandardScaler())]),\n",
       " 'pipeline-2': Pipeline(steps=[('simpleimputer',\n",
       "                  SimpleImputer(fill_value='missing', strategy='constant')),\n",
       "                 ('onehotencoder',\n",
       "                  OneHotEncoder(handle_unknown='ignore', sparse=False))]),\n",
       " 'pipeline-3': Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='most_frequent')),\n",
       "                 ('onehotencoder',\n",
       "                  OneHotEncoder(drop='if_binary', dtype=<class 'int'>))]),\n",
       " 'drop': 'drop'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adapted from lec 10\n",
    "preprocessor.fit_transform(X_train)\n",
    "preprocessor.named_transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account length</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>...</th>\n",
       "      <th>state_VT</th>\n",
       "      <th>state_WA</th>\n",
       "      <th>state_WI</th>\n",
       "      <th>state_WV</th>\n",
       "      <th>state_WY</th>\n",
       "      <th>area code_408</th>\n",
       "      <th>area code_415</th>\n",
       "      <th>area code_510</th>\n",
       "      <th>international plan_yes</th>\n",
       "      <th>voice mail plan_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>-0.767893</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.618769</td>\n",
       "      <td>-0.721211</td>\n",
       "      <td>0.618927</td>\n",
       "      <td>0.069871</td>\n",
       "      <td>-1.156734</td>\n",
       "      <td>0.069926</td>\n",
       "      <td>1.088667</td>\n",
       "      <td>0.052115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>-0.843585</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-1.293778</td>\n",
       "      <td>1.655252</td>\n",
       "      <td>-1.293517</td>\n",
       "      <td>-1.167277</td>\n",
       "      <td>-1.207278</td>\n",
       "      <td>-1.166291</td>\n",
       "      <td>-2.162302</td>\n",
       "      <td>-0.720990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>0.544113</td>\n",
       "      <td>1.900976</td>\n",
       "      <td>-0.609809</td>\n",
       "      <td>0.169963</td>\n",
       "      <td>-0.609654</td>\n",
       "      <td>-2.210130</td>\n",
       "      <td>0.157417</td>\n",
       "      <td>-2.211244</td>\n",
       "      <td>0.369287</td>\n",
       "      <td>-0.463288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>0.165650</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>0.998345</td>\n",
       "      <td>-0.473663</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>-0.754894</td>\n",
       "      <td>0.258506</td>\n",
       "      <td>-0.755774</td>\n",
       "      <td>1.597736</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>0.115188</td>\n",
       "      <td>-0.587624</td>\n",
       "      <td>-0.994886</td>\n",
       "      <td>0.764078</td>\n",
       "      <td>-0.994731</td>\n",
       "      <td>1.195994</td>\n",
       "      <td>-0.246937</td>\n",
       "      <td>1.196515</td>\n",
       "      <td>0.793839</td>\n",
       "      <td>0.206736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      account length  number vmail messages  total day minutes  \\\n",
       "1402       -0.767893              -0.587624           0.618769   \n",
       "1855       -0.843585              -0.587624          -1.293778   \n",
       "633         0.544113               1.900976          -0.609809   \n",
       "1483        0.165650              -0.587624           0.998345   \n",
       "2638        0.115188              -0.587624          -0.994886   \n",
       "\n",
       "      total day calls  total day charge  total eve minutes  total eve calls  \\\n",
       "1402        -0.721211          0.618927           0.069871        -1.156734   \n",
       "1855         1.655252         -1.293517          -1.167277        -1.207278   \n",
       "633          0.169963         -0.609654          -2.210130         0.157417   \n",
       "1483        -0.473663          0.998611          -0.754894         0.258506   \n",
       "2638         0.764078         -0.994731           1.195994        -0.246937   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  ...  state_VT  \\\n",
       "1402          0.069926             1.088667           0.052115  ...       0.0   \n",
       "1855         -1.166291            -2.162302          -0.720990  ...       0.0   \n",
       "633          -2.211244             0.369287          -0.463288  ...       0.0   \n",
       "1483         -0.755774             1.597736           0.000574  ...       0.0   \n",
       "2638          1.196515             0.793839           0.206736  ...       0.0   \n",
       "\n",
       "      state_WA  state_WI  state_WV  state_WY  area code_408  area code_415  \\\n",
       "1402       0.0       0.0       0.0       0.0            0.0            1.0   \n",
       "1855       0.0       1.0       0.0       0.0            0.0            0.0   \n",
       "633        0.0       0.0       0.0       0.0            0.0            1.0   \n",
       "1483       0.0       0.0       0.0       0.0            0.0            0.0   \n",
       "2638       0.0       0.0       0.0       0.0            0.0            0.0   \n",
       "\n",
       "      area code_510  international plan_yes  voice mail plan_yes  \n",
       "1402            0.0                     0.0                  0.0  \n",
       "1855            1.0                     0.0                  0.0  \n",
       "633             0.0                     0.0                  1.0  \n",
       "1483            1.0                     1.0                  0.0  \n",
       "2638            1.0                     0.0                  0.0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_columns = list(\n",
    "    preprocessor.named_transformers_[\"pipeline-2\"]\n",
    "    .named_steps[\"onehotencoder\"]\n",
    "    .get_feature_names(categorical_features)\n",
    ")\n",
    "ohe_columns2 = list(\n",
    "    preprocessor.named_transformers_[\"pipeline-3\"]\n",
    "    .named_steps[\"onehotencoder\"]\n",
    "    .get_feature_names(binary_features)\n",
    ")\n",
    "new_columns = numeric_features + ohe_columns + ohe_columns2\n",
    "X_train_enc = pd.DataFrame(\n",
    "    preprocessor.transform(X_train), index=X_train.index, columns=new_columns\n",
    ")\n",
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 area code feature\n",
    "rubric={points:4}\n",
    "\n",
    "The original dataset had a feature called `area code`. Let's assume we encoded this feature with one-hot encoding.\n",
    "\n",
    "1. The area codes were numbers to begin with. Why do we want to use one-hot encoding on this feature?\n",
    "2. What were the possible values of `area code`? \n",
    "3. What new feature(s) were created to replace `area code`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415    1178\n",
       "408     588\n",
       "510     567\n",
       "Name: area code, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"area code\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These area codes are not continuous, so each individual area code represents a location, much like how text would represent whatever the text says. Therefore, this numeric feature isn't actually numeric, but rather categorical. Therefore, we need to do one-hot-encoding on it. \n",
    "The possible values of area code were 415, 408 and 510\n",
    "The new features created were \"area code_408\", \"area code_415\", and \"area code_510\" which represent whether the example's area code is indeed that feature's (the feature would output a 1 if so)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Dummy classifier\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Create a `DummyClassifier`. Report the following scoring metrics via cross-validation: accuracy, precision, recall, f1-score. Briefly comment on your results, including any warnings the code produces (2 sentences max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.850482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.850482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.850482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015003</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.851931</td>\n",
       "      <td>0.850027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015001</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.850562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy  test_f1  train_f1  \\\n",
       "0  0.016000    0.009501       0.850107        0.850482      0.0       0.0   \n",
       "1  0.015000    0.008497       0.850107        0.850482      0.0       0.0   \n",
       "2  0.018500    0.011500       0.850107        0.850482      0.0       0.0   \n",
       "3  0.015003    0.008499       0.851931        0.850027      0.0       0.0   \n",
       "4  0.015001    0.009001       0.849785        0.850562      0.0       0.0   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0          0.0           0.0             0.0              0.0  \n",
       "1          0.0           0.0             0.0              0.0  \n",
       "2          0.0           0.0             0.0              0.0  \n",
       "3          0.0           0.0             0.0              0.0  \n",
       "4          0.0           0.0             0.0              0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "#taken from lec 9\n",
    "pipedum = make_pipeline(\n",
    "    preprocessor, DummyClassifier()\n",
    ")\n",
    "\n",
    "scoring = [\n",
    "    \"accuracy\",\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"precision\",\n",
    "]  # scoring can be a string, a list, or a dictionary\n",
    "scores = cross_validate(\n",
    "    pipedum, X_train, y_train, return_train_score=True, scoring=scoring\n",
    ")\n",
    "\n",
    "\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have a fairly high accuracy, but 0 for everything else. The scoring is counting \"churn\" = true as the positive case (default parameter for these scoring says pos_label = 1, and in this case \"churn = True\" is label 1 and \"churn = False\" is label 0), so because the dummy classifier is always outputting false (as false is the most common in y_train), we have that our true positive is always 0. Therefore, for recall, precision, and f1, we have a score of 0 due to having no true positives.. or any predicted positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Logistic regression\n",
    "rubric={points:8} \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Train and score a logistic regression classifier on the dataset. \n",
    "2. Report the same metrics as in the previous part.\n",
    "3. Are you satisfied with the results? Use your `DummyClassifier` results as a reference point. Discuss in a few sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.869379</td>\n",
       "      <td>0.864416</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.332454</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.852248</td>\n",
       "      <td>0.868167</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.362694</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.250896</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.654206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033501</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.867095</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.364103</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.254480</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.639640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031001</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>0.869099</td>\n",
       "      <td>0.863953</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.345361</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.239286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032496</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.839056</td>\n",
       "      <td>0.868773</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.373402</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.261649</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.651786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.035500    0.008500       0.869379        0.864416  0.371134  0.332454   \n",
       "1  0.033500    0.008501       0.852248        0.868167  0.273684  0.362694   \n",
       "2  0.033501    0.009501       0.850107        0.867095  0.255319  0.364103   \n",
       "3  0.031001    0.008502       0.869099        0.863953  0.371134  0.345361   \n",
       "4  0.032496    0.008003       0.839056        0.868773  0.242424  0.373402   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.257143      0.225806        0.666667         0.630000  \n",
       "1     0.185714      0.250896        0.520000         0.654206  \n",
       "2     0.171429      0.254480        0.500000         0.639640  \n",
       "3     0.260870      0.239286        0.642857         0.620370  \n",
       "4     0.171429      0.261649        0.413793         0.651786  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelr = make_pipeline(\n",
    "    preprocessor, LogisticRegression()\n",
    ")\n",
    "scores2 = cross_validate(\n",
    "    pipelr, X_train, y_train, return_train_score=True, scoring=scoring\n",
    ")\n",
    "\n",
    "pd.DataFrame(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the test accuracy is around the same area as the dummy classifier, which is good as we don't ever want to perform worse than that. That being said, the results are still not satisfying as the recall and f1 scores are very low. This suggests that the amount of true positives(churn = True) we managed to predict is incredibly low. Precision is a little higher, suggesting that we don't have a lot of predicted positives in the first place. This demonstrates the effect of having a large class imbalance, as the number of false cases overwhelm the true cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Logistic regression with `class_weight`\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Set the `class_weight` parameter of your logistic regression model to `'balanced'` and report the same metrics as in the previous part. \n",
    "2. Do you prefer this model to the one in the previous part? Discuss your results in a few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041998</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.785867</td>\n",
       "      <td>0.769561</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.497664</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.369151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.768737</td>\n",
       "      <td>0.771168</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.372852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.008501</td>\n",
       "      <td>0.764454</td>\n",
       "      <td>0.774384</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.511034</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.788530</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.378007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.779325</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.517564</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.789286</td>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.385017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039502</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.786824</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.531765</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.810036</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.395797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.041998    0.012000       0.785867        0.769561  0.489796  0.497664   \n",
       "1  0.042500    0.008500       0.768737        0.771168  0.490566  0.504065   \n",
       "2  0.038002    0.008501       0.764454        0.774384  0.455446  0.511034   \n",
       "3  0.036999    0.008500       0.751073        0.779325  0.462963  0.517564   \n",
       "4  0.039502    0.007999       0.733906        0.786824  0.436364  0.531765   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.685714      0.763441        0.380952         0.369151  \n",
       "1     0.742857      0.777778        0.366197         0.372852  \n",
       "2     0.657143      0.788530        0.348485         0.378007  \n",
       "3     0.724638      0.789286        0.340136         0.385017  \n",
       "4     0.685714      0.810036        0.320000         0.395797  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelr2 = make_pipeline(\n",
    "    preprocessor, LogisticRegression(class_weight = 'balanced')\n",
    ")\n",
    "scores3 = cross_validate(\n",
    "    pipelr2, X_train, y_train, return_train_score=True, scoring=scoring\n",
    ")\n",
    "pd.DataFrame(scores3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do prefer this one a little more than the previous model. Since we see that recall is higher, we know that we managed to predict quite a good number of true positives ('churn' = True) in a dataset with overwhelming number of negative cases. Therefore, we can see the power of the class weight balancing. Precision is lower because we will have made positive cases more impactful, so a byproduct of that is it will predict true more often. Given that the dataset is still overwhelmingly negative, we will have a fair number of false positives. That being said, it does create a better balance of recall and precision, demonstrated by the f1 score, which is roughly 15% higher than the previous model. While the accuracy is a bit lower than the dummy classifier, but accuracy isn't a good metric when there is a large class imbalance like there is in this dataset.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Hyperparameter optimization\n",
    "rubric={points:10}\n",
    "\n",
    "Now let's tune the hyperparameters of our `LogisticRegression` using `GridSearchCV` to maximize cross-validation f1 score. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Jointly optimize `C` (choose some reasonable values) and `class_weight` (`None` vs. `'balanced'`) with `GridSearchCV` and `scoring=\"f1\"`. \n",
    "2. What values of `C` and `class_weight` are chosen and what is the best cross-validation f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced'}\n",
      "0.47873599874436196\n"
     ]
    }
   ],
   "source": [
    "# values taken from last homework and slighly modified to include more\n",
    "C_vals = 10.0 ** np.arange(-3, 3, 0.5)\n",
    "\n",
    "train_scores = []\n",
    "cv_scores = []\n",
    "\n",
    "param_grid = {\n",
    "    \"logisticregression__C\": C_vals,\n",
    "    \"logisticregression__class_weight\": [None, 'balanced'],\n",
    "}\n",
    "pipelr3 = make_pipeline(\n",
    "    preprocessor, LogisticRegression()\n",
    ")\n",
    "grid_search = GridSearchCV(\n",
    "    pipelr3, param_grid, cv=5, n_jobs=-1, return_train_score=True, scoring='f1'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train) # all the work is done here\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best hyperparamters are a value of C=0.1 and the class_weight set to balanced. The cv f1 score for these hyperparamters is 0.4787."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Test results\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Evaluate the best model on the test set. In particular show each of the following on the test set:  \n",
    "    - Confusion matrix. \n",
    "    - Classification report. \n",
    "    - Precision-recall curve with average precision score.     \n",
    "    - ROC curve with AUC. \n",
    "3. Comment on the results.    \n",
    "\n",
    "> Note that we are not doing it here but in real life, you would also plot confusion matrix, precision-recall curve, and ROC curve on validation data to examine errors and to choose a threshold which works for your operating point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.77      0.85       866\n",
      "        True       0.34      0.76      0.47       134\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.65      0.77      0.66      1000\n",
      "weighted avg       0.87      0.77      0.80      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\miniconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "pipelr4 = pipelr3 = make_pipeline(\n",
    "    preprocessor, LogisticRegression(C=0.1, class_weight='balanced')\n",
    ")\n",
    "\n",
    "pipelr4.fit(X_train, y_train)\n",
    "disp = plot_confusion_matrix(\n",
    "    pipelr4,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    cmap=plt.cm.Blues,\n",
    "    colorbar=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, pipelr4.predict(X_test)\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we have a fairly low number of false negatives so we have a high precision for the negatives, we do have a decently high number of false positives and therefore have low positive precision. We can definitely see that using weighted average increase the predictive power of the model if we look at the macro averages vs weighted averages. Given that we have a massive imbalance between classes, this is also a good sign as \"true\" is an uncommon occurance and we want our model to catch that. Recall is even for both, demonstrating that it does do a nice job at identifying their respective class examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26019889fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, pipelr4.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "plt.plot(precision, recall, label=\"logistic regression: PR curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(\n",
    "    precision_score(y_train, pipelr4.predict(X_train)),\n",
    "    recall_score(y_train, pipelr4.predict(X_train)),\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we would want a curve that hits the top right, but we can see that this curve goes nowhere near that far. Here we have high recall but low precisions. Increasing the threshold looks like it will drop recall significantly, but only slightly increase precision, does not seem like a good tradeoff. On the other hand, if we lower then threshold, we see that our recall will increase, but our precision will decrease at roughly the same rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for logistic regression: 0.823\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pipelr4.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[default_threshold],\n",
    "    tpr[default_threshold],\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_lr = roc_auc_score(y_test, pipelr4.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC for logistic regression: {:.3f}\".format(roc_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can see here that the ROC curve's shape is how we want it to look. The curve should be near the upper left, and while it isn't completely there in this case, it is relatively close. As for the area under curve, we have a fairly high AUC, telling us that if we were to pick a random positive point, it would likely have a higher score than a randomly picked point from the negative class, according to the classifier. This tells us that while it is fairly good at distinguishing between positive points and negative points, it does struggle and misidentify. It is definitely better than if it were 0.5, which would just be randomly classifying the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression metrics <a name=\"3\"></a>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from `sklearn datasets`. The code below loads the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Data spitting and exploration \n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (80%) and test (20%) splits. \n",
    "2. Explore the train split. Do you need to apply any transformations on the data? If yes, create a preprocessor with the appropriate transformations. \n",
    "3. Separate `X` and `y` in train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train, house_test = train_test_split(housing_df, test_size=0.2, random_state=123)\n",
    "house_train\n",
    "numeric_features=house_train.drop(columns=[\"MedHouseVal\"]).columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessorreg = make_column_transformer(\n",
    "    (make_pipeline(SimpleImputer(), StandardScaler()), numeric_features),\n",
    ")\n",
    "\n",
    "\n",
    "X_trainh = house_train.drop(columns=[\"MedHouseVal\"])\n",
    "X_testh = house_test.drop(columns=[\"MedHouseVal\"])\n",
    "\n",
    "y_trainh = house_train[\"MedHouseVal\"]\n",
    "y_testh = house_test[\"MedHouseVal\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale the dataset given that each feature has a vastly different scale from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baseline: DummyRegressor \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out cross-validation using `DummyRegressor` with default scoring. \n",
    "2. What metric is used for scoring by default? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.006898\n",
       "score_time     0.002100\n",
       "test_score    -0.000147\n",
       "train_score    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelinereg = make_pipeline(\n",
    "    preprocessorreg, DummyRegressor()\n",
    ")\n",
    "\n",
    "scores = pd.DataFrame(cross_validate(\n",
    "    pipelinereg, X_trainh, y_trainh, cv=5, return_train_score=True))\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default metric for all of sklearn regression is R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Different regressors\n",
    "rubric={points:8}\n",
    "\n",
    "In this exercise, we are going to use [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model which we haven't looked into yet. At this point you should feel comfortable using models with our usual ML workflow even if you don't know the details. We'll talk about `RandomForestRegressor` later in the course.  \n",
    "\n",
    "The code below defines a custom scorer called `mape_scorer` and creates dictionaries for different regressors (`models`) and different scoring metrics (`score_types_reg`). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the `models` and the evaluation metrics `score_types_reg` in the code below, carry out cross-validation with each model, by passing the evaluation metrics to `scoring` argument of `cross_validate`. Use a pipeline with the model as an estimator if you are applying any transformations. \n",
    "2. Show results as a dataframe. \n",
    "3. Interpret the results. How do the models compare to the baseline? Which model seems to be performing well with different metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_neg_mean_squared_error</th>\n",
       "      <th>test_neg_root_mean_squared_error</th>\n",
       "      <th>test_neg_mean_absolute_error</th>\n",
       "      <th>test_r2</th>\n",
       "      <th>test_mape_scorer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>-0.683433</td>\n",
       "      <td>-0.810381</td>\n",
       "      <td>-0.535444</td>\n",
       "      <td>0.481744</td>\n",
       "      <td>-31.979551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>6.3901</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>-0.264792</td>\n",
       "      <td>-0.514451</td>\n",
       "      <td>-0.335683</td>\n",
       "      <td>0.800980</td>\n",
       "      <td>-18.926472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               fit_time  score_time  test_neg_mean_squared_error  \\\n",
       "Ridge            0.0080      0.0033                    -0.683433   \n",
       "Random Forest    6.3901      0.0735                    -0.264792   \n",
       "\n",
       "               test_neg_root_mean_squared_error  test_neg_mean_absolute_error  \\\n",
       "Ridge                                 -0.810381                     -0.535444   \n",
       "Random Forest                         -0.514451                     -0.335683   \n",
       "\n",
       "                test_r2  test_mape_scorer  \n",
       "Ridge          0.481744        -31.979551  \n",
       "Random Forest  0.800980        -18.926472  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "# make a scorer function that we can pass into cross-validation\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"mape_scorer\": mape_scorer,\n",
    "}\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for model in models:\n",
    "    newpipe = make_pipeline(\n",
    "        preprocessorreg, models[model]\n",
    "    )\n",
    "    results_dict[model] = pd.DataFrame(cross_validate(newpipe, X_trainh, y_trainh,\n",
    "                            scoring=score_types_reg)).mean()\n",
    "    \n",
    "pd.DataFrame(results_dict).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dummyclassifier uses r2 score, so if we compare that, we see that the r2 is much better in these two models as we want it to be as close to 1 as possible. We see that the random forest is the best out of the three classifiers we've seen in that regard. Otherwsise, we see that the three mean errors have a close to 0 error which is good, with random forest performing better. Lastly, for mape, we see Random Forest doing better than Ridge in this metric as the value is closer to 0 Although, it is still a decently big error as it is nearly 20%. As such, Random Forest seems to be doing the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 3.4 Hyperparameter optimization \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out hyperparameter optimization using `RandomizedSearchCV` and `Ridge` with the following `param_dist`. The `alpha` hyperparameter of `Ridge` controls the fundamental tradeoff. Choose the metric of your choice for hyperparameter optimization. \n",
    "2. Are you getting better scores compared to the default values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ridge__alpha': 0.002269252227374439}\n",
      "-0.81037027024494\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "param_dist = {\"ridge__alpha\": loguniform(1e-3, 1e3)}\n",
    "\n",
    "newpipe2 = make_pipeline(\n",
    "    preprocessorreg, Ridge()\n",
    ")\n",
    "\n",
    "rand_search = RandomizedSearchCV(newpipe2, param_dist, n_jobs = -1, scoring = \"neg_root_mean_squared_error\")\n",
    "rand_search.fit(X_trainh, y_trainh)\n",
    "\n",
    "print(rand_search.best_params_)\n",
    "print(rand_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the neg_root_mean_squared_error with our best found value for alpha seems to get us a root mean squared error of 0.81037 vs the default's 0.81038. This is means it is marginally better than the default value and thus, does perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test results\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try the best model on the test set.\n",
    "2. Briefly comment on the results. (1 to 2 sentences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set score is: 0.8151070945474366\n"
     ]
    }
   ],
   "source": [
    "newpipe3 = make_pipeline(\n",
    "    preprocessorreg, RandomForestRegressor()\n",
    ")\n",
    "\n",
    "newpipe3.fit(X_trainh, y_trainh)\n",
    "print(\"The testing set score is:\", newpipe3.score(X_testh, y_testh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the testing set score is 0.8145, using sklearns default scoring system of R^2, which is better than the cv score of 0.8019 that we found earlier using the R^2 metric. As such, our model is very close to our cross-validation score, which is good for trustworthyness, and also higher than the score which means it generalizes well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model interpretation  \n",
    "rubric={points:4}\n",
    "\n",
    "Ridge is a linear model and it learns coefficients associated with each feature during `fit()`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Visualize coefficients learned by the `Ridge` model above as a pandas dataframe with two columns: features and coefficients. If you attempted 3.4, use the `Ridge` model with best hyperparameters. Otherwise use the `Ridge` model with default hyperparameters. \n",
    "2. Increasing which feature values would result in higher housing price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MedInc</td>\n",
       "      <td>0.836010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AveBedrms</td>\n",
       "      <td>0.318289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HouseAge</td>\n",
       "      <td>0.115221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Population</td>\n",
       "      <td>-0.007404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AveOccup</td>\n",
       "      <td>-0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AveRooms</td>\n",
       "      <td>-0.281901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-0.855547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-0.890148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  coefficients\n",
       "0      MedInc      0.836010\n",
       "3   AveBedrms      0.318289\n",
       "1    HouseAge      0.115221\n",
       "4  Population     -0.007404\n",
       "5    AveOccup     -0.041683\n",
       "2    AveRooms     -0.281901\n",
       "7   Longitude     -0.855547\n",
       "6    Latitude     -0.890148"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipefinal = make_pipeline(preprocessorreg, Ridge(alpha=rand_search.best_params_['ridge__alpha']))\n",
    "pipefinal.fit(X_trainh, y_trainh)\n",
    "                          \n",
    "new_cols = numeric_features                          \n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"features\": new_cols,\n",
    "        \"coefficients\": pipefinal.named_steps[\"ridge\"].coef_,\n",
    "    }\n",
    ")\n",
    "df.sort_values(\"coefficients\",ascending=False)\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the MedInc AveBedrms, and HouseAge features would result in a higher housing price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "name": "_merged",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
